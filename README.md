# MLPR-Lab5-Spring-Sem3-2026
Machine Learning and Pattern Recognition – Lab 5 (Spring 2026)

Here are the questions answered

Q1. What are the common distance metrics used in distance-based classification algorithms?

Common distance metrics are Euclidean distance, Manhattan distance, Minkowski distance, Chebyshev distance, Hamming distance, and Cosine distance (similarity-based).

Q2. What are some real-world applications of distance-based classification algorithms?

They are used in face recognition, recommendation systems, medical diagnosis, text classification, image recognition, fraud detection, and pattern recognition.

Q3. Explain various distance metrics.

Euclidean Distance: Straight-line distance between two points.

Manhattan Distance: Sum of absolute differences between coordinates.

Minkowski Distance: General form of Euclidean and Manhattan (controlled by a parameter p).

Chebyshev Distance: Maximum absolute difference between coordinates.

Hamming Distance: Counts number of positions where two binary strings differ.

Cosine Distance: Measures angle difference between two vectors.

Q4. What is the role of cross validation in model performance?

Cross validation helps check how well a model performs on unseen data. It reduces overfitting and gives a more reliable estimate of accuracy.

Q5. Explain variance and bias in terms of KNN?

In KNN:

Small K → Low bias, High variance (model overfits).

Large K → High bias, Low variance (model underfits).
Choosing the right K balances bias and variance.
